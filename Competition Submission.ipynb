{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afd1035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nltk.download('punkt', 'stopwords', 'wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8707024",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1439c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrn = np.load('/Users/dorisveronicaavedikian/Desktop/Spring 2022/CSCI 6366/Paper and Competition /csci6366-data-mining-competition-utrgv/y_train.npy').ravel()\n",
    "xtrn = open('X_train.txt','r', encoding = 'utf-8').readlines()\n",
    "xtest = open('X_test.txt','r', encoding = 'utf-8').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112856e",
   "metadata": {},
   "source": [
    "We use the following code to process and create a dictionary of all words present across all the documents. \n",
    "The dictionary will contain all unique words across the corpus and each word in the dictionary will be treated \n",
    "as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52c1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of unique words or features:  5658\n",
      "Random Sample: ['olds', 'drying', 'stunning', 'safes', 'stupid', 'charging', 'playthrough', 'realistic', 'negeves', 'shelter']\n"
     ]
    }
   ],
   "source": [
    "count_vectorize = CountVectorizer()\n",
    "feature_vector = count_vectorize.fit(xtrn)\n",
    "features = feature_vector.get_feature_names()\n",
    "print(\"Total # of unique words or features: \", len(features))\n",
    "print(\"Random Sample:\", random.sample(features, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3140b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions (# of Reviews, # of Features): (1000, 5658)\n"
     ]
    }
   ],
   "source": [
    "train_features = count_vectorize.transform(xtrn)\n",
    "print(\"Dimensions (# of Reviews, # of Features):\", train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0b02f",
   "metadata": {},
   "source": [
    "**Function to preprocess the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fea19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData(data_to_clean):\n",
    "    \n",
    "    clean_data=[]\n",
    "    ps=PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    removewords = ['peopl', 'much', 'go', 'make', 'realli', 'thing', 'well', \n",
    "            'even', 'time', 'one', 'still', 'tri', 'get', 'also', 'way', 'first', 'say']\n",
    "    \n",
    "    stopwords_nltk = stopwords.words('english')\n",
    "    removewords += stopwords_nltk\n",
    "    \n",
    "    for text in data_to_clean:\n",
    "        review = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "        \n",
    "        stemlem = [ps.stem(k) and wnl.lemmatize(k) for k in word_tokenize(review) if not k\n",
    "                     in set(stopwords.words('english'))]\n",
    "        \n",
    "        for word in stemlem:\n",
    "            if word in removewords:\n",
    "                stemlem.remove(word)\n",
    "                \n",
    "        clean_text = ' '.join(stemlem)\n",
    "        clean_data.append(clean_text)\n",
    "        \n",
    "    return(clean_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a275be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = pd.DataFrame({'Before': xtrn,'Label': ytrn})\n",
    "test_data = pd.DataFrame({'Before': xtest})\n",
    "\n",
    "clean_xtrn, clean_xtest = [CleanData(k) for k in [xtrn, xtest]]\n",
    "\n",
    "trn_data['After'] = clean_xtrn\n",
    "test_data['After'] = clean_xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50051fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique words after cleaning data:  4825\n"
     ]
    }
   ],
   "source": [
    "count_vectorize = CountVectorizer()\n",
    "feature_vector = count_vectorize.fit(clean_xtrn)\n",
    "features = feature_vector.get_feature_names()\n",
    "print(\"# of unique words after cleaning data: \", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb71319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions after cleaning (# of Reviews, # of Features): (1000, 4825)\n"
     ]
    }
   ],
   "source": [
    "train_features = count_vectorize.transform(clean_xtrn)\n",
    "print(\"Dimensions after cleaning (# of Reviews, # of Features):\", train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aeb9a0",
   "metadata": {},
   "source": [
    "The following feature count was used after cleaning the data to determine which words were showing up the most \n",
    "that arent traditional english stop words and might not be helpful (i.m.o) but are repeated a lot. The feature count after \n",
    "cleaning was used to come up with the list of words in \"removewords\" above in CleanData(data_to_clean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "578fc89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>game</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>bad</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>play</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>like</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>good</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>fun</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>would</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>great</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>really</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>buy</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>player</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>people</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>best</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>played</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>gameplay</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>hour</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>want</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>playing</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>friend</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>story</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  counts\n",
       "1718      game    1439\n",
       "298        bad     879\n",
       "3137      play     237\n",
       "2436      like     226\n",
       "1820      good     195\n",
       "1693       fun     167\n",
       "4769     would     133\n",
       "1845     great     131\n",
       "3424    really     126\n",
       "526        buy     107\n",
       "3144    player      95\n",
       "3062    people      90\n",
       "379       best      85\n",
       "3142    played      83\n",
       "1725  gameplay      82\n",
       "2042      hour      80\n",
       "4643      want      80\n",
       "3147   playing      78\n",
       "1675    friend      74\n",
       "4093     story      70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorize = CountVectorizer()\n",
    "\n",
    "feature_vector = count_vectorize.fit(clean_xtrn)\n",
    "features = feature_vector.get_feature_names()\n",
    "\n",
    "train_ds_features = count_vectorize.transform(clean_xtrn)\n",
    "feature_counts=np.sum(train_ds_features.toarray(), axis=0)\n",
    "\n",
    "feature_counts=pd.DataFrame(dict(features = features, counts = feature_counts))\n",
    "feature_counts.sort_values('counts', ascending=False) [0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4463f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>great game play it like everyday i recomend th...</td>\n",
       "      <td>great game play like everyday recomend everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>its just relly fun\\n</td>\n",
       "      <td>relly fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>i don't like high textures, sorry.\\n</td>\n",
       "      <td>like high texture sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>meow meow!\\n</td>\n",
       "      <td>meow meow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>takes a long time to finish each matches, and ...</td>\n",
       "      <td>take long finish match anyways im tf item lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Before  \\\n",
       "8    great game play it like everyday i recomend th...   \n",
       "276                               its just relly fun\\n   \n",
       "835               i don't like high textures, sorry.\\n   \n",
       "95                                        meow meow!\\n   \n",
       "845  takes a long time to finish each matches, and ...   \n",
       "\n",
       "                                               After  \n",
       "8    great game play like everyday recomend everyone  \n",
       "276                                        relly fun  \n",
       "835                          like high texture sorry  \n",
       "95                                         meow meow  \n",
       "845    take long finish match anyways im tf item lol  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_data[['Before', 'After']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee38530",
   "metadata": {},
   "source": [
    "**Training Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d20570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xval, ytr, yval = train_test_split(trn_data.After, ytrn, test_size= 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73e3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "tfidf_vec = TfidfTransformer()\n",
    "\n",
    "xtrn_vec = vec.fit_transform(xtr)\n",
    "xtrn_tfidf1 = tfidf_vec.fit_transform(xtrn_vec)\n",
    "xtest_vec = vec.transform(xval)\n",
    "xtest_tfidf1 = tfidf_vec.transform(xtest_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5482a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 / Logistic Regression Accuracy\n",
      "Training: 0.9625\n",
      "Testing: 0.805\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "x = model1.fit(xtrn_tfidf1, ytr)\n",
    "print(\"Model 1 / Logistic Regression Accuracy\")\n",
    "print(\"Training:\", accuracy_score(ytr, x.predict(xtrn_tfidf1)))\n",
    "print(\"Testing:\", accuracy_score(yval, x.predict(xtest_tfidf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "580279f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 / LinearSVC Accuracy\n",
      "Training: 0.99625\n",
      "Testing: 0.79\n"
     ]
    }
   ],
   "source": [
    "model2 = LinearSVC()\n",
    "x = model2.fit(xtrn_tfidf1, ytr)\n",
    "print(\"Model 2 / LinearSVC Accuracy\")\n",
    "print(\"Training:\", accuracy_score(ytr, x.predict(xtrn_tfidf1)))\n",
    "print(\"Testing:\", accuracy_score(yval, x.predict(xtest_tfidf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "847a5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 / MLPClassifier Accuracy\n",
      "Training: 0.9975\n",
      "Testing: 0.775\n"
     ]
    }
   ],
   "source": [
    "model3 = MLPClassifier()\n",
    "x = model3.fit(xtrn_tfidf1, ytr)\n",
    "print(\"Model 3 / MLPClassifier Accuracy\")\n",
    "print(\"Training:\", accuracy_score(ytr, x.predict(xtrn_tfidf1)))\n",
    "print(\"Testing:\", accuracy_score(yval, x.predict(xtest_tfidf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ab940cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 / MultinomialNB Accuracy\n",
      "Training: 0.97625\n",
      "Testing: 0.79\n"
     ]
    }
   ],
   "source": [
    "model4 = MultinomialNB()\n",
    "x = model4.fit(xtrn_tfidf1, ytr)\n",
    "print(\"Model 4 / MultinomialNB Accuracy\")\n",
    "print(\"Training:\", accuracy_score(ytr, x.predict(xtrn_tfidf1)))\n",
    "print(\"Testing:\", accuracy_score(yval, x.predict(xtest_tfidf1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc04a2",
   "metadata": {},
   "source": [
    "**Final Models - Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015d4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "tfidf_vec = TfidfTransformer()\n",
    "\n",
    "xtrn_vec = vec.fit_transform(trn_data.After)\n",
    "xtrn_tfidf1 = tfidf_vec.fit_transform(xtrn_vec)\n",
    "xtest_vec = vec.transform(test_data.After)\n",
    "xtest_tfidf1 = tfidf_vec.transform(xtest_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b27dba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC = LinearSVC()\n",
    "LSVC.fit(xtrn_tfidf1, ytrn)\n",
    "ypred = LSVC.predict(xtest_tfidf1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = range(1, xtest_tfidf1.shape[0] + 1)\n",
    "df['label'] = ypred\n",
    "df.to_csv('LSVC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1754b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier()\n",
    "MLP.fit(xtrn_tfidf1, ytrn)\n",
    "pred_test = MLP.predict(xtest_tfidf1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = range(1, xtest_tfidf1.shape[0] + 1)\n",
    "df['label'] = pred_test\n",
    "df.to_csv('MLP.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ec13bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(xtrn_tfidf1, ytrn)\n",
    "ypred=lg.predict(xtest_tfidf1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = range(1, xtest_tfidf1.shape[0] + 1)\n",
    "df['label'] = ypred\n",
    "df.to_csv('LG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185d0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(xtrn_tfidf1, ytrn)\n",
    "ypred=lg.predict(xtest_tfidf1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = range(1, xtest_tfidf1.shape[0] + 1)\n",
    "df['label'] = ypred\n",
    "df.to_csv('NB.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
